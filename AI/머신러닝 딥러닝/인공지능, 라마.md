# 우리 스스로가 AI를 준비해야 하는 이유 TED
AI는 적은양의 데이터로도 잘 작동할 수 있다.
만들어놓고 획일적으로 적용할 AI 시스템을 만드느것이 어렵다.
Long Tail문제. 2:8의 법칙과 반대로 역파레토법칙이라 불림.
초기에는 얻기쉬운 흔한 데이터 셋(20%)으로 모델을 학습시키는것이 경제적이고 쉽다. 80%의 일을 할수있다
예측 정확도를 높이고 오류를 줄이려면 롱테일에 대한 데이터셋으로 학습시켜야 한다. 이것은 얻기가 매우 어렵다.
트레이닝을 시켜도 얻을수 있는 가치는 적다.
하지만 이 비주류 데이터셋이 부족하면 결과적으로 완성도에 큰 영향을 미친다.
니치시장은 계속해서 성장. 계속해서 꼬리가 길어진다. 현재는 이 꼬리가 굉장히 골칫거리. 
그렇다면 중소기업과 개인들이 자신에게 꼭 필요한 AI시스템을 구축하려면 어떻게 해야 할까?
석판, 끌보다 펜과 종이가 문맹 퇴치의 중요한 수단이 되었던 것처럼
새로운 AI개발 플랫폼이 부상하고 있다. 많은 코드를 작성하는것에서 데이터를 요구하는것으로 바뀌고 있다.
카메라로 찍어 올리고 무엇이 에러인지 표시


# ChatGPT
OpenAI에서 공개. 
일론머스크 등 여러명이 극찬!

GPT3.5버전으로 2021년까지 학습된 데이터를 기반으로 한다.
1750억개의 파라미터 신경망을 통해 학습
GPT는 Generative Pre Training의 약자
  다음에 어떤 단어가 나오면 적절할지 계속 판단
  이전에는 MS의 Turing NLG 모델은 100억개 파라미터였음. 
  3.5버전에서는 전체문장에 대한 사람의 판단도 검사해서 보정.
  GPT4는 100조개.  academic에는 이미 검증된 수준이다. 단 현재는 돈이 너무 많이 든다.
chatGPT는 묻는말에 따라서 새로운 데이터가 생성되는 개념이다. 모방과 창조의 경계가 더욱 모호해졌다.
구글 검색엔진이 사라질지도 모른다는 전망
사람 개개인에 맞춰서 퍼스널라이징 될 수 있다.

<실습>
구글에서 OpenAI들어가서 Try ChatGPT클릭
한글로 적어도된다.


# 이미지 생성기
### Midjourney
  디스코드 쓸수 있어야함.
  가장저렴한 요금제 한달에 만원정도에 3시간
### Stable Diffusion
  내 컴퓨터의 그래픽카드나 colab 이용
  모델다운
  초보자가 하기 힘듦. 미세작업 가능
### Dall-E 2
### Bing Image Creator
설치, 가입대기, 요금 없음
Dall-E 가 엔진으로 사용됨

# LLama3
설치 쉽게 하려면 allama
15T학습
META에서 오픈소스로 공개
영어에 최적화. 멀티모달 안되고 텍스트만 처리 가능
csv나 엑셀 못읽으니 json으로 변환해야함
한번인풋에 최대 8000 토큰
모델크기는 1/10이며 무료인것이 가장 큰 특징
8B 모델과 70B 모델은 공개되었고 400B 짜리 초거대모델은 아직 학습중
라마3 8B는 라마2 13B를 압도
라마3 8B instruction은 라마2 70B조차 뛰어넘는다.
그런데 훨씬 작은 8B모델이 더 성능이 좋다는 소문이 AI업계에서 돌고있음



- 이준범님이 만든 한국어모델(https://huggingface.co/beomi/Llama-3-Open-Ko-8B)
- 서울과기대 MLP연구실에서 임경태 박사님(Bllossom)
- [인도인 영상](https://www.youtube.com/watch?v=j6ghgVMS4Ng)
- 야놀자에서 공개한 EEVE로 따라해보기(https://github.com/teddylee777/langserve_ollama)
	- https://www.youtube.com/watch?v=VkcaigvTrug
	- 올라마 다운, 설치하면 윈도우에서는 우측하단 올라마 아이콘
	- 허깅페이스에서 GGUF 파일 다운 (GGUF : GPT Generated Unified Format)
		- pip install huggingface-hub
		- 직접 다운로드 버튼으로 다운 또는 명령어로 다운
			- 직접받을 경우
				- https://huggingface.co/heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF/tree/main 의 Files and versions 탭
				- 내가 집컴퓨터에 깐 위치 : C:\AI\ollama\gguf\EEVE-Korean-Instruct-10.8B-v1.0-GGUF
			- 명렁어로 받을 경우  2번째줄 : 리포지토리이름,  3번째줄 : 모델
			  huggingface-cli download \
			  heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF \
			  ggml-model-Q5_K_M.gguf \
			  --local-dir 본인의_컴퓨터_다운로드폴더_경로 \
			  --local-dir-use-symlinks False
		- 일반적으로 Modelfile이라는 이름으로 모델위치, 템플릿, 온도 등 설정
		- 올라마 실행 :  (5분정도 걸려서 인스톨됨)
		  ollama create EEVE-Korean-10.8B -f Modelfile
		- 실행코드 설명 : 올라마생성명령어 내가지정한이름 -파일 모델파일까지의경로
		- ollama list로 확인  (7.7GB 보임)
		- 테스트 :   ollama run EEVE-Korean-10.8B:latest
		- 단점 : 커맨드창이라 편집, 붙여넣기가 쉽지 않음. 첫번째답하고나서 뒤에 계속 이상한소리함
	- 올라마에서 구현하여 LangServe로 배포(11:15)
		- 랭서브는 streamlit을 대체할 수 있을까?(https://www.youtube.com/watch?v=mdzMBF56HOM&list=PLIMb_GuNnFweShkx8-yorSjhwGKv9raR_&index=17) 인데 인코딩 에러나서 못해봄
			- fastapi기반임
			- 랭서브 올라마 소스(https://github.com/teddylee777/langserve_ollama)
				- 내컴퓨터 위치 : C:\AI\ollama\gguf\langserve_ollama-main\app
				- .env파일 세팅해야함
				- langsmith (랭체인에서 만든 온라인 기반의 LLM 어플리케이션 모니터링, 테스트, 배포 지원 도구) 사이트에 가입하고 프로젝트 생성후 API KEY  생성

				- poetry설치와 실행

		- 랭서브에서 올라마 체인 생성  chain.py
		- 대화를 수행하는 템플릿 chat.py
		- server.py 에서 라우팅


### gpt 4 all
https://www.youtube.com/watch?v=Je2Y-QEZMX0
올라마 보다 더 쉬운 사용과 온디바이스 설치임. 그런데 배포가 안되는듯. 그래서 컴퓨터가 안좋으면 사용하기 어렵네.

https://gpt4all.io/index.html
C:\Users\ggoom\gpt4all
187메가. 설치하고 나면 GPT4ALL이라고 나뭇가지 뻗어나간 서비스 생김. 실행시키고 필요한 모델 다운
- 아직 한글에 문제가 있음

다운로드 경로 설정(나는 디폴트)  로 3개 설치함
C:/Users/ggoom/AppData/Local/nomic.ai/GPT4All/
1. 순수 라마3  
2. 한국어로 파인튜닝 된거 korean 검색해서 teddylee777의 EEVE-Instruct-10.8B-v1.0-gguf 다운
3. chatGPT-4는 api키만 넣어주면 설치없이 됨
모델 선택
Application General Settings에서 GPU등 선택

