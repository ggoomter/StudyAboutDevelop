# 우리 스스로가 AI를 준비해야 하는 이유 TED
AI는 적은양의 데이터로도 잘 작동할 수 있다.
만들어놓고 획일적으로 적용할 AI 시스템을 만드느것이 어렵다.
Long Tail문제. 2:8의 법칙과 반대로 역파레토법칙이라 불림.
초기에는 얻기쉬운 흔한 데이터 셋(20%)으로 모델을 학습시키는것이 경제적이고 쉽다. 80%의 일을 할수있다
예측 정확도를 높이고 오류를 줄이려면 롱테일에 대한 데이터셋으로 학습시켜야 한다. 이것은 얻기가 매우 어렵다.
트레이닝을 시켜도 얻을수 있는 가치는 적다.
하지만 이 비주류 데이터셋이 부족하면 결과적으로 완성도에 큰 영향을 미친다.
니치시장은 계속해서 성장. 계속해서 꼬리가 길어진다. 현재는 이 꼬리가 굉장히 골칫거리. 
그렇다면 중소기업과 개인들이 자신에게 꼭 필요한 AI시스템을 구축하려면 어떻게 해야 할까?
석판, 끌보다 펜과 종이가 문맹 퇴치의 중요한 수단이 되었던 것처럼
새로운 AI개발 플랫폼이 부상하고 있다. 많은 코드를 작성하는것에서 데이터를 요구하는것으로 바뀌고 있다.
카메라로 찍어 올리고 무엇이 에러인지 표시


# ChatGPT
OpenAI에서 공개. 
일론머스크 등 여러명이 극찬!

GPT3.5버전으로 2021년까지 학습된 데이터를 기반으로 한다.
1750억개의 파라미터 신경망을 통해 학습
GPT는 Generative Pre Training의 약자
  다음에 어떤 단어가 나오면 적절할지 계속 판단
  이전에는 MS의 Turing NLG 모델은 100억개 파라미터였음. 
  3.5버전에서는 전체문장에 대한 사람의 판단도 검사해서 보정.
  GPT4는 100조개.  academic에는 이미 검증된 수준이다. 단 현재는 돈이 너무 많이 든다.
chatGPT는 묻는말에 따라서 새로운 데이터가 생성되는 개념이다. 모방과 창조의 경계가 더욱 모호해졌다.
구글 검색엔진이 사라질지도 모른다는 전망
사람 개개인에 맞춰서 퍼스널라이징 될 수 있다.

<실습>
구글에서 OpenAI들어가서 Try ChatGPT클릭
한글로 적어도된다.


# 이미지 생성기
### Midjourney
  디스코드 쓸수 있어야함.
  가장저렴한 요금제 한달에 만원정도에 3시간
### Stable Diffusion
  내 컴퓨터의 그래픽카드나 colab 이용
  모델다운
  초보자가 하기 힘듦. 미세작업 가능
### Dall-E 2
### Bing Image Creator
설치, 가입대기, 요금 없음
Dall-E 가 엔진으로 사용됨

# LLama3
설치 쉽게 하려면 allama
15T학습
META에서 오픈소스로 공개
8B 모델과 70B 모델
그런데 훨씬 작은 8B모델이 더 성능이 좋다는 소문이 AI업계에서 돌고있음
2024년 4월15일에는 400B짜리 모델 개발중이라고 발표

- 이준범님이 만든 한국어모델(https://huggingface.co/beomi/Llama-3-Open-Ko-8B)
- 서울과기대 MLP연구실에서 임경태 박사님(Bllossom)
- 야놀자에서 공개한 EEVE로 따라해보기(https://github.com/teddylee777/langserve_ollama)
	- https://www.youtube.com/watch?v=VkcaigvTrug
	- 올라마 다운, 설치하면 윈도우에서는 우측하단 올라마 아이콘
	- 허깅페이스에서 GGUF 파일 다운 (GGUF : GPT Generated Unified Format)
		- pip install huggingface-hub
		- 직접 다운로드 버튼으로 다운 또는 명령어로 다운
			- 직접받을 경우
				- https://huggingface.co/heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF/tree/main 의 Files and versions 탭
			- 명렁어로 받을 경우  2번째줄 : 리포지토리이름,  3번째줄 : 모델
			  huggingface-cli download \
			  heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF \
			  ggml-model-Q5_K_M.gguf \
			  --local-dir 본인의_컴퓨터_다운로드폴더_경로 \
			  --local-dir-use-symlinks False
		- 일반적으로 Modelfile이라는 이름으로 모델위치, 템플릿, 온도 등 설정
		- 올라마 실행 :  (5분정도 걸려서 인스톨됨)
		  ollama create EEVE-Korean-10.8B -f Modelfile
		- 실행코드 설명 : 올라마생성명령어 내가지정한이름 -파일 모델파일까지의경로
		- ollama list로 확인  (7.7GB 보임)
		- 테스트 :   ollama run EEVE-Korean-10.8B:latest
		- 단점 : 커맨드창이라 편집, 붙여넣기가 쉽지 않음. 첫번째답하고나서 뒤에 계속 이상한소리함
	- 올라마에서 구현하여 LangServe로 배포
		- 랭서브에서 올라마 체인 생성  chain.py
		- 대화를 수행하는 템플릿 chat.py
		- server.py 에서 라우팅
	- 